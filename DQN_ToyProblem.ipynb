{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76413096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os # for creating directories\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2645376",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = 10*10 #10x10 matrix data, do np.reshape([100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4af2d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.reshape(np.reshape(np.arange(100), [10,10]), [100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2652e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cadbf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d20fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b017783",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_output/ToyProblem/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9707d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "547c74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000) # double-ended queue; acts like list, but elements can be added/removed from either end\n",
    "        self.gamma = 1 #0.95 # decay or discount rate: enables agent to take into account future actions in addition to the immediate ones, but discounted at this rate\n",
    "        self.epsilon = 0.99 # exploration rate: how much to act randomly; more initially than later due to epsilon decay\n",
    "        self.epsilon_decay = 0.9995 # decrease number of random explorations as the agent's performance (hopefully) improves over time\n",
    "        self.epsilon_min = 0.01 # minimum amount of random exploration permitted\n",
    "        self.learning_rate = 0.001 # rate at which NN adjusts models parameters via SGD to reduce cost \n",
    "        self.model = self._build_model() # private method \n",
    "    \n",
    "    def _build_model(self):\n",
    "        # neural net to approximate Q-value function:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(5, input_dim=self.state_size, activation='relu')) # 1st hidden layer; states as input\n",
    "        #model.add(Dense(24, activation='relu')) #add move layers, for CNN\n",
    "        model.add(Dense(self.action_size, activation='linear')) # 2 actions, so 2 output neurons: 0 and 1 (L/R)\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done)) # list of previous experiences, enabling re-training later\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon: # if acting randomly, take random action\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state) # if not acting randomly, predict reward value based on current state\n",
    "        return np.argmax(act_values[0]) # pick the action that will give the highest reward (i.e., go left or right?)\n",
    "\n",
    "    def replay(self, batch_size): # method that trains NN with experiences sampled from memory\n",
    "        minibatch = random.sample(self.memory, batch_size) # sample a minibatch from memory\n",
    "        for state, action, reward, next_state, done in minibatch: # extract data for each minibatch sample\n",
    "            target = reward # if done (boolean whether game ended or not, i.e., whether final state or not), then target = reward\n",
    "            if not done: # if not done, then predict future discounted reward\n",
    "                target = (reward + self.gamma * # (target) = reward + (discount rate gamma) * \n",
    "                          np.amax(self.model.predict(next_state)[0])) # (maximum target Q based on future action a')\n",
    "            target_f = self.model.predict(state) # approximately map current state to future discounted reward\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0) # single epoch of training with x=state, y=target_f; fit decreases loss btwn target_f and y_hat\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa7b8d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent(state_size, action_size) # initialise agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d67d7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DQNAgent at 0x7f9ea7a29eb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49f508ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_state = np.zeros([10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4d2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = start_state # reset state at start of each new episode of the game\n",
    "state = np.reshape(state, [1, state_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99a3673b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7dac13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state2D = np.reshape(state, [10,10])\n",
    "state2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e57a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(Dense(5, input_dim=16, activation='relu')) # 1st hidden layer; states as input\n",
    "#model.add(Dense(4, activation='linear')) # 2 actions, so 2 output neurons: 0 and 1 (L/R)\n",
    "#model.compile(loss='mse',\n",
    "#              optimizer=Adam(lr=0.03))\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d0d0b25",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(\u001b[43mmodel\u001b[49m, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = agent.act(state) + 1\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4017ca3d",
   "metadata": {},
   "source": [
    "# Toy problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9efe932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up actions:\n",
    "\n",
    "def movef(action, position):\n",
    "    moved = False\n",
    "    newposition = position #make the new position the current position, so position does not change if move is invalid\n",
    "    if action == 1 and position[1] != 9: #right\n",
    "        newposition = [position[0], position[1]+1]\n",
    "        moved == True\n",
    "    if action == 2 and position[0] != 0: #up\n",
    "        newposition = [position[0]-1, position[1]]\n",
    "        moved == True\n",
    "    if action == 3 and position[1] != 0: #left\n",
    "        newposition = [position[0], position[1]-1]\n",
    "        moved == True\n",
    "    if action == 4 and position[0] != 9: #down\n",
    "        newposition = [position[0] + 1, position[1]]\n",
    "        moved == True\n",
    "    return newposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fd4db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSreward(real, fit):\n",
    "    real = np.array(real)\n",
    "    fit = np.array(fit)\n",
    "    RMS = np.sqrt(np.average((real - fit)**2))\n",
    "    reward = 1/(RMS + 0.01)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2927f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up subsurface model:\n",
    "\n",
    "M = np.zeros([10,10]) #generate grid of zeros\n",
    "tlc = [random.randint(0,5),random.randint(0,5)] #top left corner\n",
    "M[tlc[0]:tlc[0] + 5, tlc[1]:tlc[1] + 5] = 1\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c1ac190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for the reward, we do ground truthing, by fitting a 5x5 square to the\n",
    "#state data, and then determining the misfit\n",
    "\n",
    "def fitstate(S): #takes in the state\n",
    "    fit = False\n",
    "\n",
    "    while(not fit):\n",
    "        #generate possible fit model:\n",
    "        fM = np.zeros([10,10]) #fit Model\n",
    "        ftlc = [random.randint(0,5),random.randint(0,5)] #fit top left corner\n",
    "        fM[ftlc[0]:ftlc[0] + 5, ftlc[1]:ftlc[1] + 5] = 1\n",
    "\n",
    "        fit = True #make fit true, but false if fit does not agree with survey\n",
    "        for i in range(len(fM)):\n",
    "            for j in range(len(fM[i])):\n",
    "                if(S[i,j] != 0 and fM[i,j] * 2 - 1 != S[i,j]):\n",
    "                    fit = False\n",
    "    return fM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69d2f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_state = np.zeros([10,10]) #original state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb5af0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = [0,0] #start at top left corner\n",
    "p = sp \n",
    "\n",
    "state = start_state + 0 # reset state at start of each new episode of the game\n",
    "state = np.reshape(state, [1, state_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36300c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9b9b433f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move  = 1\n",
    "p = movef(move, p)\n",
    "state2D = np.reshape(state, [10,10])+0\n",
    "state2D[p[0], p[1]] = M[p[0], p[1]] * 2 - 1\n",
    "#state = np.reshape(state2D, [1, state_size])\n",
    "state2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a35cf8c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "df7fb50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4fae8f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent(state_size, action_size) # initialise agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "929f83de",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "824c80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state2D_list = [] #NEED TO CHANGE THIS TO A TENSOR, 2ND DIMENSION IS PATH HISTORY!!!! \n",
    "#THEN CHANGE INPUT VECTOR TO CNN!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "53734a3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "1\n",
      "6\n",
      "0\n",
      "7\n",
      "0\n",
      "8\n",
      "4\n",
      "9\n",
      "1\n",
      "10\n",
      "1\n",
      "11\n",
      "4\n",
      "12\n",
      "4\n",
      "13\n",
      "0\n",
      "14\n",
      "1\n",
      "15\n",
      "1\n",
      "16\n",
      "0\n",
      "17\n",
      "0\n",
      "18\n",
      "0\n",
      "19\n",
      "4\n",
      "20\n",
      "1\n",
      "21\n",
      "1\n",
      "22\n",
      "0\n",
      "23\n",
      "1\n",
      "24\n",
      "0\n",
      "25\n",
      "1\n",
      "26\n",
      "0\n",
      "27\n",
      "0\n",
      "28\n",
      "0\n",
      "29\n",
      "0\n",
      "30\n",
      "4\n",
      "31\n",
      "1\n",
      "32\n",
      "1\n",
      "33\n",
      "1\n",
      "34\n",
      "1\n",
      "35\n",
      "0\n",
      "36\n",
      "0\n",
      "37\n",
      "0\n",
      "38\n",
      "0\n",
      "39\n",
      "4\n",
      "40\n",
      "4\n",
      "41\n",
      "4\n",
      "42\n",
      "0\n",
      "43\n",
      "0\n",
      "44\n",
      "0\n",
      "45\n",
      "0\n",
      "46\n",
      "0\n",
      "47\n",
      "4\n",
      "48\n",
      "0\n",
      "49\n",
      "1\n",
      "50\n",
      "1\n",
      "51\n",
      "0\n",
      "52\n",
      "0\n",
      "53\n",
      "0\n",
      "54\n",
      "1\n",
      "55\n",
      "0\n",
      "56\n",
      "0\n",
      "57\n",
      "0\n",
      "58\n",
      "0\n",
      "59\n",
      "0\n",
      "60\n",
      "1\n",
      "61\n",
      "4\n",
      "62\n",
      "1\n",
      "63\n",
      "1\n",
      "64\n",
      "1\n",
      "65\n",
      "1\n",
      "66\n",
      "0\n",
      "67\n",
      "0\n",
      "68\n",
      "1\n",
      "69\n",
      "0\n",
      "70\n",
      "0\n",
      "71\n",
      "1\n",
      "72\n",
      "0\n",
      "73\n",
      "4\n",
      "74\n",
      "1\n",
      "75\n",
      "0\n",
      "76\n",
      "0\n",
      "77\n",
      "0\n",
      "78\n",
      "0\n",
      "79\n",
      "0\n",
      "80\n",
      "4\n",
      "81\n",
      "1\n",
      "82\n",
      "0\n",
      "83\n",
      "0\n",
      "84\n",
      "4\n",
      "85\n",
      "0\n",
      "86\n",
      "1\n",
      "87\n",
      "0\n",
      "88\n",
      "1\n",
      "89\n",
      "0\n",
      "90\n",
      "1\n",
      "91\n",
      "0\n",
      "92\n",
      "0\n",
      "93\n",
      "1\n",
      "94\n",
      "1\n",
      "95\n",
      "1\n",
      "96\n",
      "1\n",
      "97\n",
      "0\n",
      "98\n",
      "1\n",
      "99\n",
      "1\n",
      "100\n",
      "1\n",
      "101\n",
      "4\n",
      "102\n",
      "0\n",
      "103\n",
      "0\n",
      "104\n",
      "0\n",
      "105\n",
      "0\n",
      "106\n",
      "4\n",
      "107\n",
      "0\n",
      "108\n",
      "0\n",
      "109\n",
      "4\n",
      "110\n",
      "4\n",
      "111\n",
      "0\n",
      "112\n",
      "0\n",
      "113\n",
      "4\n",
      "114\n",
      "0\n",
      "115\n",
      "0\n",
      "116\n",
      "1\n",
      "117\n",
      "0\n",
      "118\n",
      "0\n",
      "119\n",
      "1\n",
      "120\n",
      "1\n",
      "121\n",
      "0\n",
      "122\n",
      "0\n",
      "123\n",
      "0\n",
      "124\n",
      "0\n",
      "125\n",
      "0\n",
      "126\n",
      "0\n",
      "127\n",
      "4\n",
      "128\n",
      "0\n",
      "129\n",
      "0\n",
      "130\n",
      "0\n",
      "131\n",
      "0\n",
      "132\n",
      "1\n",
      "133\n",
      "0\n",
      "134\n",
      "1\n",
      "135\n",
      "0\n",
      "136\n",
      "1\n",
      "137\n",
      "0\n",
      "138\n",
      "4\n",
      "139\n",
      "4\n",
      "140\n",
      "0\n",
      "141\n",
      "0\n",
      "142\n",
      "0\n",
      "143\n",
      "0\n",
      "144\n",
      "0\n",
      "145\n",
      "4\n",
      "146\n",
      "0\n",
      "147\n",
      "0\n",
      "148\n",
      "4\n",
      "149\n",
      "4\n",
      "150\n",
      "1\n",
      "151\n",
      "0\n",
      "152\n",
      "0\n",
      "153\n",
      "1\n",
      "154\n",
      "1\n",
      "155\n",
      "0\n",
      "156\n",
      "0\n",
      "157\n",
      "0\n",
      "158\n",
      "0\n",
      "159\n",
      "0\n",
      "160\n",
      "4\n",
      "161\n",
      "0\n",
      "162\n",
      "1\n",
      "163\n",
      "1\n",
      "164\n",
      "1\n",
      "165\n",
      "4\n",
      "166\n",
      "1\n",
      "167\n",
      "0\n",
      "168\n",
      "1\n",
      "169\n",
      "1\n",
      "170\n",
      "0\n",
      "171\n",
      "0\n",
      "172\n",
      "0\n",
      "173\n",
      "1\n",
      "174\n",
      "0\n",
      "175\n",
      "0\n",
      "176\n",
      "1\n",
      "177\n",
      "0\n",
      "178\n",
      "0\n",
      "179\n",
      "0\n",
      "180\n",
      "0\n",
      "181\n",
      "1\n",
      "182\n",
      "4\n",
      "183\n",
      "0\n",
      "184\n",
      "1\n",
      "185\n",
      "4\n",
      "186\n",
      "0\n",
      "187\n",
      "4\n",
      "188\n",
      "0\n",
      "189\n",
      "4\n",
      "190\n",
      "1\n",
      "191\n",
      "4\n",
      "192\n",
      "0\n",
      "193\n",
      "0\n",
      "194\n",
      "0\n",
      "195\n",
      "1\n",
      "196\n",
      "0\n",
      "197\n",
      "0\n",
      "198\n",
      "4\n",
      "199\n",
      "0\n",
      "200\n",
      "1\n",
      "201\n",
      "1\n",
      "202\n",
      "0\n",
      "203\n",
      "0\n",
      "204\n",
      "0\n",
      "205\n",
      "0\n",
      "206\n",
      "4\n",
      "207\n",
      "0\n",
      "208\n",
      "1\n",
      "209\n",
      "0\n",
      "210\n",
      "0\n",
      "211\n",
      "1\n",
      "212\n",
      "0\n",
      "213\n",
      "0\n",
      "214\n",
      "1\n",
      "215\n",
      "1\n",
      "216\n",
      "0\n",
      "217\n",
      "0\n",
      "218\n",
      "0\n",
      "219\n",
      "0\n",
      "220\n",
      "0\n",
      "221\n",
      "1\n",
      "222\n",
      "0\n",
      "223\n",
      "1\n",
      "224\n",
      "0\n",
      "225\n",
      "1\n",
      "226\n",
      "1\n",
      "227\n",
      "0\n",
      "228\n",
      "0\n",
      "229\n",
      "0\n",
      "230\n",
      "4\n",
      "231\n",
      "0\n",
      "232\n",
      "0\n",
      "233\n",
      "0\n",
      "234\n",
      "1\n",
      "235\n",
      "0\n",
      "236\n",
      "1\n",
      "237\n",
      "0\n",
      "238\n",
      "1\n",
      "239\n",
      "0\n",
      "240\n",
      "4\n",
      "241\n",
      "0\n",
      "242\n",
      "0\n",
      "243\n",
      "0\n",
      "244\n",
      "0\n",
      "245\n",
      "0\n",
      "246\n",
      "0\n",
      "247\n",
      "0\n",
      "248\n",
      "1\n",
      "249\n",
      "0\n",
      "250\n",
      "0\n",
      "251\n",
      "1\n",
      "252\n",
      "0\n",
      "253\n",
      "0\n",
      "254\n",
      "1\n",
      "255\n",
      "0\n",
      "256\n",
      "4\n",
      "257\n",
      "0\n",
      "258\n",
      "0\n",
      "259\n",
      "0\n",
      "260\n",
      "0\n",
      "261\n",
      "0\n",
      "262\n",
      "0\n",
      "263\n",
      "0\n",
      "264\n",
      "0\n",
      "265\n",
      "1\n",
      "266\n",
      "0\n",
      "267\n",
      "0\n",
      "268\n",
      "0\n",
      "269\n",
      "0\n",
      "270\n",
      "0\n",
      "271\n",
      "0\n",
      "272\n",
      "0\n",
      "273\n",
      "1\n",
      "274\n",
      "4\n",
      "275\n",
      "0\n",
      "276\n",
      "0\n",
      "277\n",
      "0\n",
      "278\n",
      "0\n",
      "279\n",
      "0\n",
      "280\n",
      "1\n",
      "281\n",
      "0\n",
      "282\n",
      "1\n",
      "283\n",
      "0\n",
      "284\n",
      "1\n",
      "285\n",
      "1\n",
      "286\n",
      "1\n",
      "287\n",
      "1\n",
      "288\n",
      "4\n",
      "289\n",
      "4\n",
      "290\n",
      "0\n",
      "291\n",
      "1\n",
      "292\n",
      "0\n",
      "293\n",
      "0\n",
      "294\n",
      "0\n",
      "295\n",
      "0\n",
      "296\n",
      "1\n",
      "297\n",
      "0\n",
      "298\n",
      "0\n",
      "299\n",
      "0\n",
      "300\n",
      "0\n",
      "301\n",
      "0\n",
      "302\n",
      "0\n",
      "303\n",
      "0\n",
      "304\n",
      "0\n",
      "305\n",
      "0\n",
      "306\n",
      "0\n",
      "307\n",
      "1\n",
      "308\n",
      "1\n",
      "309\n",
      "4\n",
      "310\n",
      "0\n",
      "311\n",
      "0\n",
      "312\n",
      "0\n",
      "313\n",
      "0\n",
      "314\n",
      "0\n",
      "315\n",
      "0\n",
      "316\n",
      "0\n",
      "317\n",
      "0\n",
      "318\n",
      "1\n",
      "319\n",
      "0\n",
      "320\n",
      "4\n",
      "321\n",
      "1\n",
      "322\n",
      "0\n",
      "323\n",
      "1\n",
      "324\n",
      "4\n",
      "325\n",
      "0\n",
      "326\n",
      "0\n",
      "327\n",
      "4\n",
      "328\n",
      "0\n",
      "329\n",
      "0\n",
      "330\n",
      "1\n",
      "331\n",
      "0\n",
      "332\n",
      "0\n",
      "333\n",
      "0\n",
      "334\n",
      "0\n",
      "335\n",
      "0\n",
      "336\n",
      "0\n",
      "337\n",
      "1\n",
      "338\n",
      "0\n",
      "339\n",
      "1\n",
      "340\n",
      "0\n",
      "341\n",
      "1\n",
      "342\n",
      "1\n",
      "343\n",
      "0\n",
      "344\n",
      "1\n",
      "345\n",
      "0\n",
      "346\n",
      "0\n",
      "347\n",
      "0\n",
      "348\n",
      "0\n",
      "349\n",
      "4\n",
      "350\n",
      "0\n",
      "351\n",
      "0\n",
      "352\n",
      "0\n",
      "353\n",
      "1\n",
      "354\n",
      "1\n",
      "355\n",
      "1\n",
      "356\n",
      "0\n",
      "357\n",
      "0\n",
      "358\n",
      "0\n",
      "359\n",
      "0\n",
      "360\n",
      "0\n",
      "361\n",
      "1\n",
      "362\n",
      "1\n",
      "363\n",
      "0\n",
      "364\n",
      "0\n",
      "365\n",
      "4\n",
      "366\n",
      "0\n",
      "367\n",
      "0\n",
      "368\n",
      "0\n",
      "369\n",
      "0\n",
      "370\n",
      "1\n",
      "371\n",
      "1\n",
      "372\n",
      "0\n",
      "373\n",
      "1\n",
      "374\n",
      "0\n",
      "375\n",
      "0\n",
      "376\n",
      "0\n",
      "377\n",
      "1\n",
      "378\n",
      "0\n",
      "379\n",
      "0\n",
      "380\n",
      "0\n",
      "381\n",
      "4\n",
      "382\n",
      "1\n",
      "383\n",
      "0\n",
      "384\n",
      "0\n",
      "385\n",
      "1\n",
      "386\n",
      "0\n",
      "387\n",
      "0\n",
      "388\n",
      "0\n",
      "389\n",
      "0\n",
      "390\n",
      "0\n",
      "391\n",
      "0\n",
      "392\n",
      "1\n",
      "393\n",
      "0\n",
      "394\n",
      "0\n",
      "395\n",
      "0\n",
      "396\n",
      "1\n",
      "397\n",
      "0\n",
      "398\n",
      "4\n",
      "399\n",
      "4\n",
      "400\n",
      "1\n",
      "401\n",
      "0\n",
      "402\n",
      "0\n",
      "403\n",
      "0\n",
      "404\n",
      "1\n",
      "405\n",
      "0\n",
      "406\n",
      "0\n",
      "407\n",
      "1\n",
      "408\n",
      "0\n",
      "409\n",
      "0\n",
      "410\n",
      "0\n",
      "411\n",
      "0\n",
      "412\n",
      "0\n",
      "413\n",
      "0\n",
      "414\n",
      "0\n",
      "415\n",
      "0\n",
      "416\n",
      "0\n",
      "417\n",
      "0\n",
      "418\n",
      "4\n",
      "419\n",
      "0\n",
      "420\n",
      "0\n",
      "421\n",
      "0\n",
      "422\n",
      "1\n",
      "423\n",
      "0\n",
      "424\n",
      "0\n",
      "425\n",
      "0\n",
      "426\n",
      "1\n",
      "427\n",
      "0\n",
      "428\n",
      "0\n",
      "429\n",
      "0\n",
      "430\n",
      "0\n",
      "431\n",
      "1\n",
      "432\n",
      "1\n",
      "433\n",
      "0\n",
      "434\n",
      "0\n",
      "435\n",
      "1\n",
      "436\n",
      "0\n",
      "437\n",
      "0\n",
      "438\n",
      "1\n",
      "439\n",
      "0\n",
      "440\n",
      "0\n",
      "441\n",
      "0\n",
      "442\n",
      "4\n",
      "443\n",
      "0\n",
      "444\n",
      "1\n",
      "445\n",
      "0\n",
      "446\n",
      "0\n",
      "447\n",
      "0\n",
      "448\n",
      "0\n",
      "449\n",
      "1\n",
      "450\n",
      "1\n",
      "451\n",
      "0\n",
      "452\n",
      "0\n",
      "453\n",
      "0\n",
      "454\n",
      "1\n",
      "455\n",
      "0\n",
      "456\n",
      "0\n",
      "457\n",
      "0\n",
      "458\n",
      "0\n",
      "459\n",
      "0\n",
      "460\n",
      "1\n",
      "461\n",
      "1\n",
      "462\n",
      "0\n",
      "463\n",
      "1\n",
      "464\n",
      "0\n",
      "465\n",
      "0\n",
      "466\n",
      "0\n",
      "467\n",
      "1\n",
      "468\n",
      "0\n",
      "469\n",
      "0\n",
      "470\n",
      "0\n",
      "471\n",
      "0\n",
      "472\n",
      "0\n",
      "473\n",
      "0\n",
      "474\n",
      "1\n",
      "475\n",
      "0\n",
      "476\n",
      "1\n",
      "477\n",
      "0\n",
      "478\n",
      "0\n",
      "479\n",
      "1\n",
      "480\n",
      "0\n",
      "481\n",
      "0\n",
      "482\n",
      "0\n",
      "483\n",
      "0\n",
      "484\n",
      "0\n",
      "485\n",
      "0\n",
      "486\n",
      "0\n",
      "487\n",
      "0\n",
      "488\n",
      "0\n",
      "489\n",
      "1\n",
      "490\n",
      "0\n",
      "491\n",
      "1\n",
      "492\n",
      "0\n",
      "493\n",
      "0\n",
      "494\n",
      "0\n",
      "495\n",
      "0\n",
      "496\n",
      "1\n",
      "497\n",
      "0\n",
      "498\n",
      "1\n",
      "499\n",
      "4\n",
      "500\n",
      "1\n",
      "501\n",
      "0\n",
      "502\n",
      "0\n",
      "503\n",
      "0\n",
      "504\n",
      "0\n",
      "505\n",
      "0\n",
      "506\n",
      "0\n",
      "507\n",
      "1\n",
      "508\n",
      "0\n",
      "509\n",
      "1\n",
      "510\n",
      "0\n",
      "511\n",
      "1\n",
      "512\n",
      "0\n",
      "513\n",
      "0\n",
      "514\n",
      "0\n",
      "515\n",
      "0\n",
      "516\n",
      "0\n",
      "517\n",
      "0\n",
      "518\n",
      "0\n",
      "519\n",
      "0\n",
      "520\n",
      "0\n",
      "521\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [129]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     state \u001b[38;5;241m=\u001b[39m next_state\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# set \"current state\" for upcoming iteration to the current next state        \u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agent\u001b[38;5;241m.\u001b[39mmemory) \u001b[38;5;241m>\u001b[39m batch_size:\n\u001b[0;32m---> 43\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# train the agent by replaying the experiences of the episode\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     45\u001b[0m     agent\u001b[38;5;241m.\u001b[39msave(output_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:04d}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [106]\u001b[0m, in \u001b[0;36mDQNAgent.replay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done: \u001b[38;5;66;03m# if not done, then predict future discounted reward\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     target \u001b[38;5;241m=\u001b[39m (reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m \u001b[38;5;66;03m# (target) = reward + (discount rate gamma) * \u001b[39;00m\n\u001b[1;32m     38\u001b[0m               np\u001b[38;5;241m.\u001b[39mamax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(next_state)[\u001b[38;5;241m0\u001b[39m])) \u001b[38;5;66;03m# (maximum target Q based on future action a')\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m target_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# approximately map current state to future discounted reward\u001b[39;00m\n\u001b[1;32m     40\u001b[0m target_f[\u001b[38;5;241m0\u001b[39m][action] \u001b[38;5;241m=\u001b[39m target\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(state, target_f, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# single epoch of training with x=state, y=target_f; fit decreases loss btwn target_f and y_hat\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1951\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1944\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   1945\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1946\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1947\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTPUStrategy and AutoShardPolicy.FILE might lead to out-of-order \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1948\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult. Consider setting it to AutoShardPolicy.DATA.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1949\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m-> 1951\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1954\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1959\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/data_adapter.py:1399\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1398\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/data_adapter.py:1149\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1146\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1148\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/data_adapter.py:328\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m    326\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mflat_map(slice_batch_indices)\n\u001b[0;32m--> 328\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    331\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffle_batch\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch):\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/data_adapter.py:360\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.slice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrab_batch\u001b[39m(i, data):\n\u001b[1;32m    358\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m d: tf\u001b[38;5;241m.\u001b[39mgather(d, i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), data)\n\u001b[0;32m--> 360\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrab_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Default optimizations are disabled to avoid the overhead of (unnecessary)\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# input pipeline graph serialization and deserialization\u001b[39;00m\n\u001b[1;32m    365\u001b[0m options \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2018\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2016\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m MapDataset(\u001b[38;5;28mself\u001b[39m, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2018\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2019\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2020\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2021\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2024\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:5234\u001b[0m, in \u001b[0;36mParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m   5233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m-> 5234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5236\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5238\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5240\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3062\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3063\u001b[0m \n\u001b[1;32m   3064\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3070\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3072\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3073\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3036\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   3038\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3039\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd_call_context(cache_key\u001b[38;5;241m.\u001b[39mcall_context)\n\u001b[0;32m-> 3292\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                          graph_function)\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3125\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3127\u001b[0m ]\n\u001b[1;32m   3128\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3129\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3142\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3143\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1202\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1196\u001b[0m   \u001b[38;5;66;03m# Returning a closed-over tensor does not trigger convert_to_tensor.\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m   func_graph\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m   1198\u001b[0m       func_graph\u001b[38;5;241m.\u001b[39mcapture(x)\n\u001b[1;32m   1199\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m flatten(func_graph\u001b[38;5;241m.\u001b[39mstructured_outputs)\n\u001b[1;32m   1200\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1202\u001b[0m   func_graph\u001b[38;5;241m.\u001b[39mvariables \u001b[38;5;241m=\u001b[39m variables\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_control_dependencies:\n\u001b[1;32m   1205\u001b[0m   func_graph\u001b[38;5;241m.\u001b[39mcontrol_outputs\u001b[38;5;241m.\u001b[39mextend(deps_control_manager\u001b[38;5;241m.\u001b[39mops_which_must_run)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/auto_control_deps.py:447\u001b[0m, in \u001b[0;36mAutomaticControlDependencies.__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# Ignore switches (they're handled separately)\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSwitch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes_module\u001b[38;5;241m.\u001b[39mresource:\n\u001b[1;32m    448\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# Make merges trigger all other computation which must run\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Don't do this. Write a transform to chains instead.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# See core/common_runtime/control_flow_deps_to_chains.cc.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2583\u001b[0m, in \u001b[0;36mOperation.type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2582\u001b[0m   \u001b[38;5;124;03m\"\"\"The type of the op (e.g. `\"MatMul\"`).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2583\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_OperationOpType\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_op\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#need to figure out how to make this learn faster...implement CNN\n",
    "n_episodes = 10000  # n games we want agent to play (default 1001)\n",
    "for e in range(n_episodes): # iterate over new episodes of the game\n",
    "    state = np.zeros([10,10]) # reset state at start of each new episode of the game\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    sp = [5,5]\n",
    "    p = sp\n",
    "    \n",
    "    M = np.zeros([10,10]) #generate random model\n",
    "    tlc = [5*random.randint(0,1),5*random.randint(0,1)]\n",
    "    M[tlc[0]:tlc[0] + 5, tlc[1]:tlc[1] + 5] = 1\n",
    "    \n",
    "    print(e)\n",
    "    timesteps = 4\n",
    "    for time in range(timesteps):  # time represents a frame of the game; goal is to keep pole upright as long as possible up to range, e.g., 500 or 5000 timesteps\n",
    "#       env.render()\n",
    "        action = agent.act(state) # action is 0,1,2,3\n",
    "        p = movef(action+1, p) #make action 1,2,3,4\n",
    "        state2D = np.reshape(state, [10,10])+0\n",
    "        state2D[p[0], p[1]] = M[p[0], p[1]] * 2 - 1\n",
    "        next_state = np.reshape(state2D, [1, state_size]) + 0\n",
    "        reward = 0\n",
    "        if(time == timesteps - 1):\n",
    "            r= 0 \n",
    "            if(state2D[5,4] != 0):\n",
    "                r+= 1\n",
    "            if(state2D[4,4] != 0):\n",
    "                r+= 1\n",
    "#             if (state2D[5,4]!= 0):\n",
    "#                 r+=1\n",
    "#             if(state2D[5,5]!= 0):\n",
    "#                 r+=1\n",
    "            reward = r**2\n",
    "            #reward = RMSreward(fitstate(state2D), M) \n",
    "            reward_list.append(reward)\n",
    "            state2D_list.append(state2D + 0)\n",
    "            print(reward)\n",
    "        \n",
    "        agent.remember(state, action, reward, next_state, False) # remember the previous timestep's state, actions, reward, etc.        \n",
    "        state = next_state+0 # set \"current state\" for upcoming iteration to the current next state        \n",
    "        \n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.replay(batch_size) # train the agent by replaying the experiences of the episode\n",
    "    if e % 50 == 0:\n",
    "        agent.save(output_dir + \"weights_\" + '{:04d}'.format(e) + \".hdf5\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a0a095f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "76e1f331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1., -1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "20454a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state2D[5,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a87341e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "58dce2e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f07b121ebb0>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.arange(len(reward_list)), reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93241a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "state2D_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2915b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
